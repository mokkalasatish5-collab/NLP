{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T18:52:21.597643Z",
     "start_time": "2025-11-23T18:52:20.897164Z"
    }
   },
   "source": "import spacy",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:53:03.918772Z",
     "start_time": "2025-11-23T18:53:03.798016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ],
   "id": "d826a38ad070c677",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain\n",
      "america\n",
      "ate\n",
      "100\n",
      "$\n",
      "of\n",
      "samosa\n",
      ".\n",
      "Then\n",
      "he\n",
      "said\n",
      "I\n",
      "can\n",
      "do\n",
      "this\n",
      "all\n",
      "day\n",
      ".\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4663ecd1b4b85a9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:55:54.697195Z",
     "start_time": "2025-11-23T18:55:54.304144Z"
    }
   },
   "cell_type": "code",
   "source": "nlp = spacy.load('en_core_web_sm')",
   "id": "421f5939cf86032",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:56:07.576797Z",
     "start_time": "2025-11-23T18:56:07.554185Z"
    }
   },
   "cell_type": "code",
   "source": "nlp.pipe_names",
   "id": "ce1abe7b1e3e3fb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:02:13.011793Z",
     "start_time": "2025-11-23T19:02:12.979077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.pos_, \"|\", token.lemma_)"
   ],
   "id": "7a1c897109c5b226",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain | PROPN | Captain\n",
      "america | PROPN | america\n",
      "ate | VERB | eat\n",
      "100 | NUM | 100\n",
      "$ | NUM | $\n",
      "of | ADP | of\n",
      "samosa | PROPN | samosa\n",
      ". | PUNCT | .\n",
      "Then | ADV | then\n",
      "he | PRON | he\n",
      "said | VERB | say\n",
      "I | PRON | I\n",
      "can | AUX | can\n",
      "do | VERB | do\n",
      "this | PRON | this\n",
      "all | DET | all\n",
      "day | NOUN | day\n",
      ". | PUNCT | .\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:02:28.498742Z",
     "start_time": "2025-11-23T19:02:28.467457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ],
   "id": "6aa7657731210a01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc ORG\n",
      "$45 billion MONEY\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:04:12.777806Z",
     "start_time": "2025-11-23T19:04:12.752992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ],
   "id": "fc60f50a074d9fd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to acquire twitter for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d73f7a65c6d28880"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Exercise",
   "id": "2f85ec86bd85395d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:26:30.287083Z",
     "start_time": "2025-11-23T19:26:30.281449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and\n",
    "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
    "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
    "'''"
   ],
   "id": "869f757d795e33ec",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:26:32.002489Z",
     "start_time": "2025-11-23T19:26:31.456151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ],
   "id": "8c005c94ec02718d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:26:32.703584Z",
     "start_time": "2025-11-23T19:26:32.650849Z"
    }
   },
   "cell_type": "code",
   "source": "text = nlp(text)",
   "id": "9dc88a57afdfcb51",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:18:41.749436Z",
     "start_time": "2025-11-23T19:18:41.738337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "propernouns = []\n",
    "for token in text:\n",
    "    print(token)\n",
    "    if token.pos_ == 'PROPN':\n",
    "        propernouns.append(token.text)\n",
    "\n",
    "print(propernouns)\n",
    "print(len(propernouns))\n",
    "\n"
   ],
   "id": "eab6f75d7123e889",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ravi\n",
      "and\n",
      "Raju\n",
      "are\n",
      "the\n",
      "best\n",
      "friends\n",
      "from\n",
      "school\n",
      "days\n",
      ".\n",
      "They\n",
      "wanted\n",
      "to\n",
      "go\n",
      "for\n",
      "a\n",
      "world\n",
      "tour\n",
      "and\n",
      "\n",
      "\n",
      "visit\n",
      "famous\n",
      "cities\n",
      "like\n",
      "Paris\n",
      ",\n",
      "London\n",
      ",\n",
      "Dubai\n",
      ",\n",
      "Rome\n",
      "etc\n",
      "and\n",
      "also\n",
      "they\n",
      "called\n",
      "their\n",
      "another\n",
      "friend\n",
      "Mohan\n",
      "to\n",
      "take\n",
      "part\n",
      "of\n",
      "this\n",
      "world\n",
      "tour\n",
      ".\n",
      "\n",
      "\n",
      "They\n",
      "started\n",
      "their\n",
      "journey\n",
      "from\n",
      "Hyderabad\n",
      "and\n",
      "spent\n",
      "next\n",
      "3\n",
      "months\n",
      "travelling\n",
      "all\n",
      "the\n",
      "wonderful\n",
      "cities\n",
      "in\n",
      "the\n",
      "world\n",
      "and\n",
      "cherish\n",
      "a\n",
      "happy\n",
      "moments\n",
      "!\n",
      "\n",
      "\n",
      "['Raju', 'Paris', 'London', 'Dubai', 'Rome', 'Mohan', 'Hyderabad']\n",
      "7\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T19:35:21.242849Z",
     "start_time": "2025-11-23T19:35:21.155841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = '''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in\n",
    "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel'''\n",
    "entities = []\n",
    "\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"ORG\":\n",
    "        entities.append(ent.text)\n",
    "print(entities)\n",
    "print(len(entities))"
   ],
   "id": "b314ce8c789330b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tesla', 'Walmart', 'Amazon', 'Microsoft', 'Google', 'Infosys', 'Reliance', 'HDFC Bank', 'Hindustan Unilever', 'Bharti Airtel']\n",
      "10\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
